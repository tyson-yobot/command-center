1. Add /voicebot_stream Route (Returns Twilio <Stream> XML)
üìÅ In app.py:
python
Copy
Edit
@app.route("/voicebot_stream", methods=["POST", "GET"])
def voicebot_stream():
    response = """<?xml version="1.0" encoding="UTF-8"?>
    <Response>
        <Connect>
            <Stream url="wss://your-replit-url/voicebot_socket"/>
        </Connect>
    </Response>"""
    return response, 200, {'Content-Type': 'application/xml'}
üîÅ This tells Twilio:

‚ÄúStart a real-time stream‚Äù

Send the call to your WebSocket AI engine

‚úÖ 2. Build voicebot_socket.py ‚Äì Real-Time Bot
Paste this file into Replit:

python
Copy
Edit
import asyncio
import websockets
import json
import base64
import os
import openai
import requests

ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
ELEVENLABS_VOICE_ID = "cjVigY5qzO86Huf0OWal"
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

async def handle_stream(websocket, path):
    conversation = [{"role": "system", "content": "You are a professional voice assistant for YoBot. Greet the caller and ask how you can help. You can transfer, schedule demos, or take messages."}]

    print("üéôÔ∏è Call connected to YoBot AI")

    try:
        async for message in websocket:
            payload = json.loads(message)

            if "media" in payload:
                audio_b64 = payload["media"]["payload"]
                audio_data = base64.b64decode(audio_b64)

                # Transcribe with OpenAI Whisper
                transcript = transcribe(audio_data)
                if not transcript:
                    continue

                print("üó£Ô∏è Caller:", transcript)
                conversation.append({"role": "user", "content": transcript})

                # GPT response
                reply = get_gpt(conversation)
                print("ü§ñ YoBot:", reply)
                conversation.append({"role": "assistant", "content": reply})

                # Speak with ElevenLabs
                elevenlabs_speak(reply)

    except websockets.exceptions.ConnectionClosed:
        print("üîö Caller hung up")

# --- Transcribe audio with OpenAI
def transcribe(audio_bytes):
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}"}
    files = {'file': ("audio.wav", audio_bytes, 'audio/wav')}
    data = {"model": "whisper-1"}

    r = requests.post("https://api.openai.com/v1/audio/transcriptions", headers=headers, files=files, data=data)
    if r.status_code == 200:
        return r.json().get("text")
    return None

# --- Get GPT response
def get_gpt(history):
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}"}
    body = {"model": "gpt-4", "messages": history}

    r = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=body)
    return r.json()['choices'][0]['message']['content']

# --- Generate speech with ElevenLabs
def elevenlabs_speak(text):
    headers = {
        "xi-api-key": ELEVENLABS_API_KEY,
        "Content-Type": "application/json"
    }
    body = {
        "text": text,
        "voice_settings": {
            "stability": 0.4,
            "similarity_boost": 0.75
        }
    }

    url = f"https://api.elevenlabs.io/v1/text-to-speech/{ELEVENLABS_VOICE_ID}/stream"
    response = requests.post(url, headers=headers, json=body, stream=True)

    # Play response (Phase 2: stream back to Twilio live)
    with open("static/reply.mp3", "wb") as f:
        for chunk in response.iter_content(chunk_size=1024):
            if chunk:
                f.write(chunk)
    print("üîä Voice response ready.")

# --- Start server
start_server = websockets.serve(handle_stream, "0.0.0.0", 8765)
asyncio.get_event_loop().run_until_complete(start_server)
asyncio.get_event_loop().run_forever()
‚úÖ Final Step: Point Twilio's voice webhook to:
arduino
Copy
Edit
https://your-replit-url/voicebot_stream
