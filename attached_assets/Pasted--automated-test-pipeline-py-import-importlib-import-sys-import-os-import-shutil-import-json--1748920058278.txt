# automated_test_pipeline.py

import importlib
import sys
import os
import shutil
import json
import requests
from datetime import datetime

# Airtable Setup
from airtable import Airtable
BASE_ID = "your_base_id"
TABLE_NAME = "Tests"
API_KEY = "your_airtable_key"
WEBHOOK_URL = "https://hooks.slack.com/services/XXX/YYY/ZZZ"  # Replace this

airtable = Airtable(BASE_ID, TABLE_NAME, API_KEY)

# Define batches manually or dynamically here
batches = [
    (1, 20, "test_suite_001_020"),
    (21, 40, "test_suite_021_040"),
    (41, 60, "test_suite_041_060"),
    (61, 80, "test_suite_061_080"),
    (81, 100, "test_suite_081_100"),
    (101, 120, "test_suite_101_120"),
    (121, 140, "test_suite_121_140"),
    (141, 160, "test_suite_141_160"),
    (161, 180, "test_suite_161_180"),
    (181, 200, "test_suite_181_200"),
    (201, 220, "test_suite_201_220")
]

# Core Execution Logic
def run_tests_in_range(start, end, test_module_name):
    test_module = importlib.import_module(test_module_name)
    for i in range(start, end + 1):
        func_name = f"test_{i:03}"
        test_func = getattr(test_module, func_name, None)
        if callable(test_func):
            print(f"â–¶ï¸ Running Test {i:03}")
            try:
                test_func()
                airtable.insert({"test_number": i, "status": "pass", "timestamp": datetime.utcnow().isoformat()})
            except Exception as e:
                airtable.insert({"test_number": i, "status": f"fail: {str(e)[:100]}", "timestamp": datetime.utcnow().isoformat()})
                print(f"âŒ Test {i:03} FAILED: {e}")
        else:
            print(f"âŒ Test {i:03} MISSING")


def fetch_logged_tests():
    records = airtable.get_all(fields=["test_number"])
    return sorted(set(int(r["fields"]["test_number"]) for r in records if "test_number" in r["fields"]))


def detect_test_gaps(expected_range, logged_tests):
    missing = [t for t in expected_range if t not in logged_tests]
    if missing:
        print(f"\nğŸš¨ MISSING TESTS: {missing}")
    else:
        print("\nâœ… All expected tests accounted for.")
    return missing


def generate_audit_trail(logged_tests):
    with open("test_audit_log.txt", "w") as f:
        for t in sorted(logged_tests):
            f.write(f"Test {t:03} - Logged âœ…\n")
    print("ğŸ“œ Audit trail written to test_audit_log.txt")


def archive_audit():
    timestamp = datetime.utcnow().strftime("%Y%m%d-%H%M%S")
    archive_name = f"test_logs_{timestamp}"
    if os.path.exists("test_audit_log.txt"):
        shutil.make_archive(archive_name, 'zip', '.', '.', logger=None)
        print(f"ğŸ“¦ Archived audit log as {archive_name}.zip")
    else:
        print("âš ï¸ No audit log found to archive.")


def notify_results(summary_text):
    timestamp = datetime.utcnow().strftime("%Y-%m-%d %H:%M UTC")
    payload = {"text": f"ğŸ§ª *Test Execution Report*\nTime: {timestamp}\n\n{summary_text}"}
    headers = {"Content-Type": "application/json"}
    try:
        response = requests.post(WEBHOOK_URL, headers=headers, data=json.dumps(payload))
        if response.status_code == 200:
            print("ğŸ“£ Notification sent successfully.")
        else:
            print(f"âš ï¸ Notification failed: {response.status_code} - {response.text}")
    except Exception as e:
        print(f"âŒ Error sending notification: {e}")


# Master Pipeline Execution
def full_test_pipeline():
    print("\nâš™ï¸ Starting Full Test Execution Cycle")
    summary_lines = []

    for start, end, module in batches:
        print(f"\nğŸš€ Executing Batch: {start}â€“{end} from {module}")
        summary_lines.append(f"Batch {start}â€“{end} | Module: {module} | Status: In Progress")
        run_tests_in_range(start, end, module)
        summary_lines[-1] = summary_lines[-1].replace("In Progress", "âœ… Completed")

    print("\nğŸ” Final Test Coverage Verification")
    full_range = range(batches[0][0], batches[-1][1] + 1)
    logged = fetch_logged_tests()
    missing = detect_test_gaps(full_range, logged)
    generate_audit_trail(logged)
    archive_audit()

    report = "\n".join(summary_lines)
    report += f"\n\n{'âš ï¸ Missing test definitions: ' + str(missing) if missing else 'âœ… All tests accounted for.'}"
    notify_results(report)
    print("\nâœ… Full Test Operation Complete. System Green.")


if __name__ == "__main__":
    full_test_pipeline()
