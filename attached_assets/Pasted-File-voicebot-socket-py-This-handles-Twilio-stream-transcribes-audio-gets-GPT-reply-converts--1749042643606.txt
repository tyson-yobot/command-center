File: voicebot_socket.py
This handles Twilio stream â†’ transcribes audio â†’ gets GPT reply â†’ converts to ElevenLabs voice â†’ streams back.

python
Copy
Edit
import asyncio
import websockets
import json
import base64
import os
import openai
import requests

# Config
ELEVENLABS_VOICE_ID = "cjVigY5qzO86Huf0OWal"
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Optional prompt memory
conversation_history = []

async def handle_stream(websocket, path):
    global conversation_history

    print("ğŸ”Œ VoiceBot WebSocket connected")

    try:
        async for message in websocket:
            data = json.loads(message)

            if "media" in data:
                audio_data = base64.b64decode(data["media"]["payload"])

                # Send to transcription (OpenAI Whisper)
                transcript = transcribe_audio(audio_data)

                if transcript:
                    print("ğŸ—£ï¸ User said:", transcript)
                    conversation_history.append({"role": "user", "content": transcript})

                    # GPT response
                    reply = get_gpt_response(conversation_history)
                    print("ğŸ¤– Bot:", reply)
                    conversation_history.append({"role": "assistant", "content": reply})

                    # Speak with ElevenLabs
                    speak_with_elevenlabs(reply)

    except websockets.exceptions.ConnectionClosed:
        print("âŒ Call ended")
        conversation_history = []

# ğŸ”¤ Transcribe
def transcribe_audio(audio_bytes):
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}"
    }
    files = {
        'file': ("audio.wav", audio_bytes, 'audio/wav')
    }
    data = {
        "model": "whisper-1"
    }
    r = requests.post("https://api.openai.com/v1/audio/transcriptions", headers=headers, files=files, data=data)
    if r.status_code == 200:
        return r.json().get("text")
    return None

# ğŸ§  GPT Reply
def get_gpt_response(history):
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}"}
    json_data = {
        "model": "gpt-4",
        "messages": history
    }
    r = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=json_data)
    return r.json()['choices'][0]['message']['content']

# ğŸ—£ï¸ ElevenLabs Voice
def speak_with_elevenlabs(text):
    headers = {
        "xi-api-key": ELEVENLABS_API_KEY,
        "Content-Type": "application/json"
    }
    body = {
        "text": text,
        "voice_settings": {
            "stability": 0.4,
            "similarity_boost": 0.75
        }
    }

    url = f"https://api.elevenlabs.io/v1/text-to-speech/{ELEVENLABS_VOICE_ID}/stream"
    response = requests.post(url, headers=headers, json=body, stream=True)

    with open("/tmp/reply.mp3", "wb") as f:
        for chunk in response.iter_content(chunk_size=1024):
            if chunk:
                f.write(chunk)

    # TODO: send /tmp/reply.mp3 back to caller (stream or inject to Twilio)

# ğŸš€ Start server
start_server = websockets.serve(handle_stream, "0.0.0.0", 8765)

asyncio.get_event_loop().run_until_complete(start_server)
asyncio.get_event_loop().run_forever()
âœ… Next Steps
ğŸ”Œ Point /voicebot_stream to wss://.../voicebot_socket

ğŸ“¤ Stream reply.mp3 back to Twilio (optional â€” will generate next)

ğŸ›  Add error handling + connection state (phase 2)